# Speaker Notes — Intro Video: Making Causal Arguments That Hold Up

## Opening Hook (30 seconds)

The Report That Almost Changed Everything
Why proving causation is harder — and more important — than you think

Let me tell you about two reports that landed on the same desk in Addis Ababa.

The first came from a program manager in Ethiopia. Her team had deployed Community Health Extension Workers across twelve woredas in Ethiopia's Amhara region. Eighteen months in, the data looked extraordinary: maternal mortality had dropped 28% in the program woredas. She wrote a fifty-page report documenting every data point. The conclusion: "Our CHEW deployment in Ethiopia caused a significant reduction in maternal mortality."

The report went to the donor. The donor sent it to their technical advisor. The technical advisor sent back one paragraph: "You've shown a correlation. You haven't shown causation. The government of Ethiopia also rolled out a new EmONC protocol in the same woredas during the same period. How do you know it was your CHEWs and not the protocol?"

The second report came from a different team working in Ethiopia's SNNPR. Their results were more modest — a 15% reduction. But their report was eight pages. It showed the correlation, traced the mechanism step by step, tested what happened when the intervention was paused, and systematically ruled out the three most likely alternative explanations. The donor funded their scale-up within a month.

Same country. Same type of program in Ethiopia. Dramatically different outcomes. And the difference wasn't the data — it was the argument.

_(pause)_

## A Little About Me (30 seconds)

My name is Matthew Kuch. I've spent the last decade working in global child health — at CHAI in Uganda, at Gavi in Geneva managing country portfolios across Kenya and Lesotho, and at Deloitte before that managing grants for USAID and DFID. I've reviewed hundreds of program evaluations and sat in rooms where causal claims were accepted, challenged, or quietly dismissed.

The pattern is always the same: the teams that can prove causation — not just show correlation — are the ones that get funded, scaled, and taken seriously. That's the skill I want to share with you today.

_(pause)_

## What This Session Is About (45 seconds)

Welcome to Making Causal Arguments That Hold Up.

This session builds on the 4-part framework from our previous session on "The Anatomy of a Good Point." If that session taught you how to structure any argument — point, reasoning, evidence, impact — this one goes deeper into one specific type of reasoning: causal claims.

In Ethiopia, arguments about cause and effect come up constantly in MNH work. Teams say their program caused an improvement. Reports say a policy gap is causing preventable deaths. Recommendations say an intervention will produce a specific outcome. These are causal claims, and they require a specific kind of proof.

This session teaches you how to provide that proof — and how to spot the gaps before someone else does.

_(pause)_

## The Framework Walkthrough (2 minutes)

_(Reference the whiteboard diagram here — the three alternatives around the central question)_

The core of this session is a diagnostic framework. Before you claim X caused Y, you need to rule out three alternative explanations.

First — common cause. Could a third factor be driving both X and Y? In Ethiopia, this often happens when government-prioritized woredas get both NGO programs *and* government investment. The programs didn't cause the better outcomes — Ethiopia's government attention caused both.

Second — coincidence. Could X and Y just happen to move together? Especially in small samples — one health center in Ethiopia, one quarter of data — random variation can look like a pattern. The test: is there a plausible mechanism connecting X to Y? If you can't explain *how* the cause produces the effect, coincidence is the more likely explanation.

Third — reversed causation. Could the direction be backwards? Maybe better-performing facilities in Ethiopia attract more supervision visits, not the other way around. This one is subtle and surprisingly common.

Once you've ruled out all three, you build your causal argument in two parts: show the correlation with data, and tell the causal story — a step-by-step chain that explains how X produces Y. Then apply the removal test: if you take X away, does Y disappear?

_(pause)_

## A Quick Example (45 seconds)

Let me walk through a complete example in under a minute. Listen for all five pieces.

"Our mentorship program reduced neonatal mortality in target health centers in Ethiopia's Amhara region."

"Health centers in Ethiopia with mentored midwives saw a 35% drop in neonatal deaths. Matched control facilities saw no change."

"Mentored midwives in Ethiopia learned neonatal resuscitation, applied it in delivery rooms, caught danger signs earlier, initiated treatment faster."

"Not common cause — controls had similar resources. Not coincidence — 35% is far beyond quarterly noise. Not reversed — facilities were randomly assigned."

"When mentors rotated out temporarily, resuscitation rates dropped within weeks."

_(pause)_

That's the complete structure. Claim, correlation, causal story, ruling out alternatives, removal test. It takes less than a minute to deliver, but it's the kind of argument that survives scrutiny.

## Who This Is For (30 seconds)

This session is for anyone who makes causal claims in their work — in Ethiopia or anywhere. If you write program evaluations, design donor reports, present recommendations to government officials, or defend your team's results in a technical review, you need this skill.

You don't need a statistics background. You need a checklist that forces you to think clearly about cause and effect before you put your claim on paper.

## What You'll Walk Away With (30 seconds)

By the end of this session, you'll have:

- A clear understanding of the difference between correlation and causation
- A 3-part diagnostic checklist to rule out alternative explanations (common cause, coincidence, reversed causation)
- The two-part structure for building a causal argument (correlation + causal story)
- The removal test for confirming causation
- A language calibration tool that matches your claim strength to your evidence

## Closing (15 seconds)

A causal argument that holds up does three things: shows the pattern, explains the mechanism, and rules out the alternatives.

Here's my challenge: think about one causal claim you've encountered recently. Can it survive the three-check test? If it can, you're ahead of most people in the room. If it can't, this session will show you exactly how to fix it.

Let's get started.
