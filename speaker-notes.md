# Speaker Notes — Making Causal Arguments That Hold Up

## Overview
This session builds on the 4-part argumentation framework from "The Anatomy of a Good Point." It focuses on one specific skill: making causal arguments — the kind of claim you make every time you say "X caused Y" in a report, a presentation, or a policy recommendation. The examples use maternal and newborn health in Ethiopia, but the skill applies anywhere you need to attribute an outcome to a cause.

## Slide: Where We Left Off

Quick recap. In our last session, we learned the 4-part framework: lead with the point, explain why it's true, give evidence by zooming in and zooming out, and land the impact.

Today we're going deeper into one specific piece — what happens when the "why it's true" is a causal claim. When someone says "our program in Ethiopia caused this outcome," that's a very specific kind of argument. And it's the kind that gets challenged the hardest.

*(pause)*

So here's today's question: when you claim X causes Y, how do you actually prove it?

## Slide: Why Causal Arguments Matter

Think about how often causal claims come up in MNH work in Ethiopia. Every single day. Imagine a consultant in a meeting telling a minister that the vacancy rate at health posts is causing preventable newborn deaths. That's a causal claim. Or a report that states Community Health Extension Workers in Ethiopia improved antenatal care coverage by 18%. That's a causal claim. And then a donor leans across the table and says: "How do you know this program in Ethiopia caused the improvement?"

*(pause)*

That last one is the killer. Because if it can't be answered — if the evidence only shows correlation but not causation — credibility takes a hit. And the next time a recommendation is made, people remember.

## Slide: The Core Problem — Section Divider

Let's start with the core problem.

## Slide: Correlation vs. Causation

This is the foundation of everything we'll cover today. Two things can move together without one causing the other.

On the left: in Ethiopia, woredas with more Community Health Extension Workers tend to have lower maternal mortality. The two move together. That's correlation.

On the right: deploying CHEWs to underserved woredas in Ethiopia *caused* maternal mortality to decline. One produced the other. That's causation.

They look similar. They sound similar. But they're making fundamentally different claims. And stakeholders in Ethiopia need to know which claim is being made.

*(pause)*

The takeaway: correlation tells you two things move together. Causation tells you one made the other happen. That distinction is the entire foundation of this session.

## Slide: The Timeline Trap

Here's the most common causal mistake, and I guarantee everyone in this room has made it. Because X happened before Y, X must have caused Y.

A CHEW training program in Ethiopia launched in January. Neonatal mortality dropped by March. Therefore the program caused the drop, right? Not necessarily. Timing alone is not proof.

Here's a real example. A new CHEW training program was rolled out in Ethiopia's Tigray region in Q1. Neonatal mortality dropped 12% by Q3. Looks great. But Ethiopia's national bed-net distribution campaign also ran during the same period. So did the training cause the drop — or did fewer malaria-related neonatal deaths?

This is what we call the timeline trap. Just because an intervention came first doesn't mean it caused what came next.

## Slide: Three Things to Rule Out — Section Divider

So how do you avoid the timeline trap? You need to rule out three things.

## Slide: The Three Alternatives

This diagram is the core framework for today. Before you claim X caused Y, you need to consider three alternative explanations.

First — common cause. Could something else be causing both X and Y? Second — coincidence. Could X and Y just happen to move together without any real connection? Third — reversed causation. Could Y actually be causing X, not the other way around?

A causal claim only holds if all three can be ruled out. Think of this as a diagnostic checklist.

## Slide: Common Cause

Let's take each one. Common cause asks: could a third factor be causing both X and Y?

In Ethiopia, we can observe that woredas with more NGO programs also have better maternal and newborn health outcomes. But both might be driven by a third factor — government prioritization under Ethiopia's Health Sector Transformation Plan. High-priority woredas in Ethiopia attract more NGOs *and* receive more government investment. The NGOs didn't cause the outcomes. Ethiopia's government prioritization caused both.

*(pause)*

Here's a concrete example. The claim: "Our safe delivery kit deployment reduced obstetric complications in Ethiopia." The challenge: the health centers in Ethiopia chosen for deployment were already higher-performing because they had stronger woreda health office leadership. That leadership is the common cause.

## Slide: Coincidence

Number two — coincidence. Could X and Y just happen to move together?

This is less dramatic but just as dangerous. The more data points tracked across Ethiopia, the more spurious correlations emerge. Especially in small samples — a single health center, one quarter of data.

A health center in Ethiopia's SNNPR introduced a new patient register the same month neonatal mortality dropped. Did the register cause the drop? Almost certainly not. The drop was within normal quarterly variation. No mechanism connects a register format to newborn survival.

The key question to ask yourself: is there a plausible *mechanism* connecting X and Y? If you can't explain *how* X would cause Y, coincidence becomes the likely explanation.

## Slide: Reversed Causation

Number three — reversed causation. This is the most subtle trap.

Consider this from Ethiopia: health posts with more supportive supervision visits have better outcomes. Seems obvious — more supervision leads to better performance. But flip it around. Maybe better-performing health posts *attract* more visits. Supervisors visit them more often because they're easier to reach and more cooperative.

The claim: "More frequent supportive supervision visits improved health post performance in Ethiopia's Oromia region." The challenge: the performance is driving the visits — not the reverse. The direction of causation is backwards.

This one is surprisingly common in program evaluation, and it's hard to spot if you're not looking for it.

## Slide: The Checklist

Here's a quick-reference tool. Before claiming X caused Y in Ethiopia, run through these three checks.

Common cause — could something else cause both? Check for confounders: Ethiopia's HSTP priority status, geography, baseline capacity, donor attention.

Coincidence — is the connection real or noise? Look for a plausible mechanism. Check sample sizes across Ethiopian woredas. Is this within normal variation?

Reversed causation — is the direction backwards? Could the outcome be driving the input? Watch for selection effects in Ethiopia's health system.

If all three checks pass, the causal claim is on solid ground. If not, the evidence needs strengthening or the language needs softening.

## Slide: Building a Causal Argument — Section Divider

Okay, so those are the three things to rule out. Now let's talk about how to build a causal argument that actually holds up.

## Slide: The Two-Part Structure

A solid causal argument has two parts. First, show the correlation — X and Y move together. Use data from Ethiopia. Second, tell the causal story — explain *how* X produces Y. That's the mechanism.

*(pause)*

The causal story is what separates a correlation from a cause. It's a chain of reasoning that explains the steps between X and Y.

Remember "Why It's True" from the Anatomy framework? The causal story *is* your "why it's true" for causal claims. Same idea, applied specifically to cause-and-effect arguments.

## Slide: What Makes a Good Causal Story

Look at these two side by side. On the left, the bad version: "We deployed CHEWs in Ethiopia and maternal mortality dropped." That's correlation only. No mechanism. You're just stating two things that happened.

On the right, the good version: "Ethiopia's CHEWs conducted home visits, which identified danger signs early, which led to faster referrals to health centers, which reduced the first and second delays in emergency obstetric care, which reduced maternal hemorrhage deaths."

*(pause)*

See the difference? The good version traces a chain of events step by step. Each link is plausible. Each link can be tested. And the audience can follow the logic from input to outcome.

A good causal story doesn't need to be complicated. It just needs to answer the question: *how* did X produce Y?

## Slide: The Removal Test

The strongest test of causation is beautifully simple: if you removed X, would Y still happen?

If you pulled Ethiopia's CHEWs out, would the improvements vanish? If you stopped the mentorship program in Ethiopia, would facility performance decline? If the answer is yes — if removing the cause removes the effect — you have strong evidence of causation.

*(pause)*

Here's what this looks like in practice. We paused the essential medicine supply chain reform for one quarter in control woredas in Ethiopia. Stockout rates climbed back to baseline. We reinstated it. Stockouts dropped again. That's evidence of causation — not just correlation. You removed the cause, the effect disappeared. You restored the cause, the effect returned.

## Slide: Putting It All Together — Section Divider

Let's put everything together with a complete example.

## Slide: Full Example

I'm going to walk through a complete causal argument, the way you'd present it. Listen for all five pieces.

"Our mentorship program reduced neonatal mortality in target health centers in Ethiopia's Amhara region."

"Health centers in Ethiopia with mentored midwives saw a 35% drop in neonatal deaths over 12 months. Matched control facilities saw no change."

"Mentored midwives in Ethiopia learned neonatal resuscitation skills, applied them in delivery rooms, recognized danger signs earlier, and initiated treatment faster."

"Not common cause — control facilities in Ethiopia had similar baseline resources. Not coincidence — a 35% drop is well beyond normal quarterly variation. Not reversed causation — facilities were randomly assigned, not self-selected."

"When mentors rotated out of two Ethiopian facilities temporarily, neonatal resuscitation rates dropped within weeks."

*(pause)*

That's the full structure. The claim. The correlation. The causal story. Ruling out the alternatives. The removal test. It takes maybe 45 seconds to deliver, but it's airtight. What would you push back on?

## Slide: Common Mistakes

Five common mistakes, and I'm guessing you'll recognize at least two.

Confusing correlation with causation. "The data from Ethiopia shows X and Y are linked" is not the same as "X caused Y."

Relying on timing alone. "It happened after our program launched in Ethiopia" — that's the timeline trap we discussed.

Ignoring common causes. This is the most frequent failure in program evaluation in Ethiopia and globally. If you don't look for confounders, you won't find them.

Skipping the causal story. If you can't explain *how* X causes Y step by step, neither can your audience.

And overclaiming from small samples. One health center in Ethiopia, one quarter of data — that's not enough to establish a pattern. Be honest about the limits of your evidence.

## Slide: Calibrate Your Language

This is one of the most practical slides in the deck. Match your claim to the strength of your evidence.

If you have a strong RCT or quasi-experimental design, you can say "X caused Y." Full stop.

Consistent correlation plus a plausible mechanism? "X likely contributed to Y."

Observed correlation, mechanism unclear? "X is associated with Y."

Single case, limited data? "X may have played a role in Y."

And if all you have is timing? "We observed Y after X, but cannot yet attribute causation."

*(pause)*

Stakeholders in Ethiopia and beyond respect precision. Overclaiming destroys credibility. You're always better off with a precise, well-supported claim than an ambitious one that falls apart under scrutiny.

## Slide: Key Takeaways

Five things to take away from today.

One — correlation is not causation. Showing X and Y move together is step one, not the finish line.

Two — rule out the three alternatives. Common cause, coincidence, reversed causation. Run through the checklist every time.

Three — tell the causal story. Trace the mechanism step by step.

Four — apply the removal test. If X disappears, does Y?

Five — calibrate your claim. Match your language to your evidence.

And the one sentence to remember: a causal argument that holds up does three things — shows the pattern, explains the mechanism, and rules out the alternatives.

## Slide: What's Next — Section Divider

Before we close, let me give you a preview of where we're headed next.

## Slide: Coming Up — Inference and Intervention

Today you learned to *make* causal arguments. You can now show the pattern, explain the mechanism, and rule out the alternatives. That's a powerful skill — and it will serve you every time you write a report or stand up in a meeting.

But here's the thing. What we've done today is still largely qualitative. You're making logical arguments about causation. The next series — called "Inference and Intervention" — takes you into the world of causal *analysis*. That means building actual causal models. And we're going to expand our lens beyond Ethiopia — we'll be looking at Uganda, Rwanda, and many other countries.

You'll learn to draw causal diagrams — DAGs — that map out cause-and-effect relationships in health systems across multiple countries. You'll learn to put numbers on those diagrams using Bayesian networks. You'll learn to use those models to make decisions — where to invest across Ethiopia, Uganda, Rwanda, and beyond, how to allocate resources across countries, and how to anticipate what implementing partners will do.

*(pause)*

It's ten chapters, and by the end, you'll have a complete analytical toolkit that works across any country context. The reasoning you learned today — correlation versus causation, the three alternatives, the causal story — that's the foundation everything else builds on. So if today felt useful, the next series is where it becomes truly powerful.

## Slide: Closing

Now go make arguments that hold up.

*(pause)*

And here's a challenge: think about one causal claim you've seen or made recently. A recommendation, a program evaluation, a report finding. Run it through today's framework. Can you show the correlation? Can you tell the causal story? Can you rule out the three alternatives? If you can, you're solid. If you can't, now you know exactly which piece is missing — and that's worth knowing before someone else points it out.
